{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf13397f-5efc-4bc0-b1a9-6f39607caaff",
   "metadata": {},
   "source": [
    "# Analiza Danych (Python) - Lekcja 1\n",
    "\n",
    "1. [Organizacja](#1.-Organizacja)\n",
    "2. [Środowisko Python (venv)](#2.-Środowisko-Python-(venv))\n",
    "3. [GitHub i GitKraken](#3.-GitHub-i-GitKraken)\n",
    "4. [Import danych](#4.-Import-danych)\n",
    "5. [Zadania](#5.-Zadania)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca0df83-991c-4f39-a2e9-0b5aa5d096b1",
   "metadata": {},
   "source": [
    "# 1. Organizacja\n",
    "\n",
    "## Kiedy i gdzie?\n",
    "\n",
    "- Grupa 2: środa 17:45-19:15 albo do 21:00 (ojej)\n",
    "- Sala: 3.13, Wydział Psychologii, ul. Banacha 2D.\n",
    "- Łatwo można mnie znaleźć i zasadniczo się nie ukrywam, ale nie dam rady być przed zajęciami (wykład) ani po zajęciach (to jest jednak przesada). Jeśli będą potrzebne dodatkowe konsultacje, to można do mnie pisać mailowo albo na Discordzie: `PanBartosz`.\n",
    "\n",
    "## Co robimy na kursie?\n",
    "\n",
    "Celem kursu jest praktyczne opanowanie pełnego cyklu pracy z danymi:\n",
    "\n",
    "- import i kontrola jakości danych,\n",
    "- czyszczenie i transformacje w `pandas`,\n",
    "- analiza eksploracyjna i wizualizacja,\n",
    "- podstawowe wnioskowanie statystyczne,\n",
    "- raportowanie wyników,\n",
    "- praca z repozytorium `Git`/`GitHub`.\n",
    "\n",
    "## Ocena\n",
    "\n",
    "1. Obecność: 10% (14/15 zajęć).\n",
    "2. Notebooki cząstkowe: 60% (`10` notebooków).\n",
    "3. Projekt końcowy: 30% (ostatnie `3-4` zajęcia).\n",
    "\n",
    "Zasady punktacji notebooków:\n",
    "\n",
    "- oddanie na zajęciach lub w dniu zajęć: `100%`,\n",
    "- oddanie przed kolejnymi zajęciami: `80%`,\n",
    "- oddanie po kolejnych zajęciach: `60%`.\n",
    "\n",
    "Arkusz ocen: jeszcze nie wiem jak to zorganizuję, ale jeśli tylko to zorganizuję, to się pojawi tutaj.\n",
    "\n",
    "Skala ocen:\n",
    "\n",
    "- `<50%` - 2\n",
    "- `50%-59%` - 3\n",
    "- `60%-69%` - 3.5\n",
    "- `70%-79%` - 4\n",
    "- `80%-89%` - 4.5\n",
    "- `90-95%` - 5\n",
    "- `95%<` - 5!\n",
    "\n",
    "## Co przygotować przed kolejnymi zajęciami?\n",
    "\n",
    "- działającego Pythona 3.11+,\n",
    "- działające środowisko `.venv`,\n",
    "- konto GitHub (najlepiej uczelniane),\n",
    "- sforkowane repozytorium kursu.\n",
    "\n",
    "## Literatura\n",
    "\n",
    "Podstawowa:\n",
    "\n",
    "- Wes McKinney, *Python for Data Analysis*.\n",
    "- Jake VanderPlas, *Python Data Science Handbook*.\n",
    "- Allen Downey, *Think Stats*.\n",
    "\n",
    "Uzupełniająca:\n",
    "\n",
    "- Peter Bruce, Andrew Bruce, Peter Gedeck, *Practical Statistics for Data Scientists*.\n",
    "- Claus O. Wilke, *Fundamentals of Data Visualization*.\n",
    "- Dokumentacja: `pandas`, `matplotlib`, `seaborn`, `statsmodels`, `git`, `GitHub`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9ff1f9-a0e0-4511-a201-34dcaeb6aaca",
   "metadata": {},
   "source": [
    "# 2. Środowisko Python (venv)\n",
    "\n",
    "## Utworzenie środowiska (tylko raz)\n",
    "\n",
    "macOS/Linux:\n",
    "\n",
    "```bash\n",
    "cd sciezka/do/projektu\n",
    "python3 -m venv .venv\n",
    "```\n",
    "\n",
    "Windows (PowerShell):\n",
    "\n",
    "```powershell\n",
    "cd sciezka\\do\\projektu\n",
    "py -m venv .venv\n",
    "```\n",
    "\n",
    "## Aktywacja środowiska (zawsze przed pracą)\n",
    "\n",
    "macOS/Linux:\n",
    "\n",
    "```bash\n",
    "source .venv/bin/activate\n",
    "```\n",
    "\n",
    "Windows (PowerShell):\n",
    "\n",
    "```powershell\n",
    ".\\.venv\\Scripts\\Activate.ps1\n",
    "```\n",
    "\n",
    "## Instalacja bibliotek\n",
    "\n",
    "```bash\n",
    "pip install pandas numpy matplotlib seaborn jupyter openpyxl\n",
    "```\n",
    "\n",
    "## Najczęstsze błędy\n",
    "\n",
    "- `python`/`pip` z innego środowiska niż `.venv`,\n",
    "- brak aktywacji środowiska przed uruchomieniem Jupyter,\n",
    "- problem z uprawnieniami PowerShell (`Set-ExecutionPolicy -Scope CurrentUser RemoteSigned`),\n",
    "- literówka w ścieżce do projektu.\n",
    "\n",
    "## Kernel Jupyter z Twojego środowiska\n",
    "\n",
    "Po aktywacji `.venv` wykonaj:\n",
    "\n",
    "```bash\n",
    "python -m pip install ipykernel\n",
    "python -m ipykernel install --user --name analiza-venv --display-name \"Python (analiza-venv)\"\n",
    "```\n",
    "\n",
    "## Start notebooka\n",
    "\n",
    "```bash\n",
    "jupyter notebook\n",
    "```\n",
    "\n",
    "Następnie w Jupyter Notebook wybierz:\n",
    "`Kernel` -> `Change kernel` -> `Python (analiza-venv)`\n",
    "\n",
    "Sprawdzenie dostępnych kerneli:\n",
    "\n",
    "```bash\n",
    "jupyter kernelspec list\n",
    "```\n",
    "\n",
    "Usunięcie kernela (opcjonalnie):\n",
    "\n",
    "```bash\n",
    "jupyter kernelspec uninstall analiza-venv\n",
    "```\n",
    "\n",
    "## Nowoczesny tooling: `uv`\n",
    "\n",
    "`uv` to nowoczesny manager środowisk i zależności dla Pythona. W praktyce jest szybszy i bardziej przewidywalny niż ręczne `pip install` bez lockfile.\n",
    "\n",
    "### Zalety `uv`\n",
    "\n",
    "- bardzo szybkie tworzenie/synchronizacja środowiska,\n",
    "- jedna komenda do odtworzenia środowiska (`uv sync`),\n",
    "- lockfile (`uv.lock`) zapewnia powtarzalność wersji,\n",
    "- wygodne uruchamianie narzędzi we właściwym środowisku (`uv run ...`).\n",
    "\n",
    "### Podstawowe komendy `uv` w tym repo\n",
    "\n",
    "```bash\n",
    "uv sync\n",
    "uv run jupyter notebook\n",
    "uv run jupyter lab\n",
    "uv run python -c \"import pandas as pd; print(pd.__version__)\"\n",
    "uv add nazwa_pakietu\n",
    "uv remove nazwa_pakietu\n",
    "uv lock\n",
    "```\n",
    "\n",
    "### Kiedy używać `venv + pip`, a kiedy `uv`?\n",
    "\n",
    "- `venv + pip`: dobre do nauki podstaw i zrozumienia mechaniki środowiska.\n",
    "- `uv`: lepsze do codziennej pracy projektowej, gdy liczy się szybkość i odtwarzalność.\n",
    "\n",
    "## Alternatywy dla `jupyter` i `jupyter_lab`\n",
    "\n",
    "Format `.ipynb` można wygodnie obsługiwać nie tylko w klasycznym Jupyter Notebook/JupyterLab.\n",
    "\n",
    "### Edytory i IDE z obsługą notebooków\n",
    "\n",
    "- **VS Code** (`Jupyter` extension): bardzo wygodna praca z notebookami i Git w jednym miejscu.\n",
    "- **PyCharm Professional**: pełna obsługa `.ipynb`, debugowanie i integracja z interpreterami.\n",
    "- **Cursor** / inne edytory oparte o VS Code: zwykle dziedziczą wsparcie dla notebooków przez rozszerzenia.\n",
    "\n",
    "### Środowiska chmurowe\n",
    "\n",
    "- **Google Colab**: szybki start bez lokalnej instalacji, dobre do krótkich eksperymentów.\n",
    "- **Kaggle Notebooks**: gotowe środowisko pod analizę danych i ML.\n",
    "- **Databricks Notebooks**: środowisko zespołowe i produkcyjne dla większych projektów danych.\n",
    "\n",
    "### Na co uważać przy alternatywach\n",
    "\n",
    "- zgodność wersji bibliotek z lokalnym projektem,\n",
    "- dostęp do lokalnych plików danych (`dane_lekcja1/`, `dane_lekcja2/`),\n",
    "- ustawienie właściwego kernela/interpretera, żeby uniknąć błędów importu.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242ea504-878c-463e-83f6-694306b46b9d",
   "metadata": {},
   "source": [
    "# 3. GitHub i GitKraken\n",
    "\n",
    "## Git vs GitHub\n",
    "\n",
    "- `Git`: system kontroli wersji (lokalna historia zmian).\n",
    "- `GitHub`: platforma do hostowania repozytoriów Git i współpracy.\n",
    "\n",
    "## Kluczowe pojęcia\n",
    "\n",
    "- repozytorium,\n",
    "- commit,\n",
    "- branch,\n",
    "- clone,\n",
    "- push / pull.\n",
    "\n",
    "## Minimalny workflow na zajęcia\n",
    "\n",
    "1. Forkujesz repozytorium tego kursu na GitHub.\n",
    "2. Klonujesz je lokalnie.\n",
    "3. Edytujesz plik.\n",
    "4. Robisz commit z czytelnym opisem.\n",
    "5. Wysyłasz zmiany (`push`).\n",
    "\n",
    "## Alternatywy dla GitKrakena\n",
    "\n",
    "GitKraken to tylko jedno z wielu narzędzi GUI do Git. Możesz używać tego, co najlepiej pasuje do Twojego workflow.\n",
    "\n",
    "### Wszystkie systemy\n",
    "\n",
    "- **CLI (`git` w terminalu)**: najbardziej uniwersalne i przewidywalne podejście.\n",
    "- **VS Code (Source Control)**: wbudowana obsługa Git + commit/push/branch bez wychodzenia z edytora.\n",
    "- **JetBrains (PyCharm/IntelliJ)**: pełna integracja Git (log, konflikty, cherry-pick, rebase).\n",
    "\n",
    "### Windows\n",
    "\n",
    "- **GitHub Desktop**: prosty start, dobre dla początkujących.\n",
    "- **SourceTree**: rozbudowany GUI dla Git.\n",
    "- **Fork**: szybki i przejrzysty klient Git.\n",
    "\n",
    "### macOS\n",
    "\n",
    "- **Tower**: dopracowane GUI dla Git na Maca.\n",
    "- **Fork**: lekki i wygodny klient Git.\n",
    "- **SourceTree**: klasyczny, darmowy klient GUI.\n",
    "\n",
    "### Linux\n",
    "\n",
    "- **Git Cola**: prosty klient GUI, często dostępny w repozytoriach systemowych.\n",
    "- **gitg**: lekki klient dla środowisk GNOME.\n",
    "- **VS Code / JetBrains + terminal**: najczęstszy praktyczny zestaw.\n",
    "\n",
    "### Rozsądna strategia na kurs\n",
    "\n",
    "- Na początku: GUI + podstawowe komendy CLI.\n",
    "- Docelowo: swobodne przechodzenie między GUI i terminalem.\n",
    "\n",
    "## Zadanie 1\n",
    "\n",
    "1. Załóż konto GitHub (mail uczelniany).\n",
    "2. Aktywuj GitHub Student Developer Pack: https://education.github.com/pack\n",
    "3. Wybierz i zainstaluj narzędzie do pracy z Git (`GitKraken`, `GitHub Desktop`, `SourceTree`, `Fork` lub sam terminal + IDE).\n",
    "4. Sklonuj repozytorium: https://github.com/ArtuDitu/AnalizaDanychPythonKurs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e92028f-4fe8-476f-9d2e-00f856e8a12d",
   "metadata": {},
   "source": [
    "# 4. Import danych\n",
    "\n",
    "## Dlaczego to ważne?\n",
    "\n",
    "- Błędy importu propagują się na całą analizę (`garbage in, garbage out`).\n",
    "- Import to nie tylko odczyt pliku, ale też decyzje o typach, brakach danych i kodowaniu.\n",
    "- Jawne parametry importu zwiększają powtarzalność analizy.\n",
    "\n",
    "## Co trzeba kontrolować przy imporcie?\n",
    "\n",
    "- separator (`sep`),\n",
    "- kodowanie (`encoding`),\n",
    "- typy kolumn (`dtype`),\n",
    "- daty (`parse_dates`),\n",
    "- oznaczenia braków danych (`na_values`),\n",
    "- wybór arkusza/kolumn/wierszy.\n",
    "\n",
    "## Najczęstsze problemy\n",
    "\n",
    "- liczby wczytane jako tekst,\n",
    "- daty jako `object`,\n",
    "- zły separator (`;` vs `,`),\n",
    "- błędne kodowanie znaków,\n",
    "- niestandardowe oznaczenia braków (`999`, `.`, `-`).\n",
    "\n",
    "## Formaty, które poznajemy\n",
    "\n",
    "| Format | Zastosowanie |\n",
    "| --- | --- |\n",
    "| CSV | uniwersalne dane tabelaryczne |\n",
    "| Excel (`.xlsx`) | dane przekazywane przez zespoły i organizacje |\n",
    "| JSON | dane z API i struktury zagnieżdżone |\n",
    "| SQL | dane relacyjne |\n",
    "\n",
    "Import danych to kontrolowany proces translacji danych z pliku do struktury w pamięci (`DataFrame`) z jawnie opisanym schematem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5633a8-aadc-483a-841c-c08e62fd209f",
   "metadata": {},
   "source": [
    "# 5. Zadania\n",
    "\n",
    "## Pliki do ćwiczeń\n",
    "\n",
    "Pliki wejściowe znajdują się w folderze `dane_lekcja1/`:\n",
    "\n",
    "- `students.csv`\n",
    "- `data_semicolon.csv`\n",
    "- `missing_values.csv`\n",
    "- `experiment.xlsx`\n",
    "- `data.json`\n",
    "- `data_nested.json`\n",
    "\n",
    "## Zadanie 2\n",
    "\n",
    "Cel: zrozumienie różnicy między domyślną inferencją typów a jawnym schematem.\n",
    "\n",
    "Instrukcja:\n",
    "\n",
    "1. Wczytaj `students.csv`.\n",
    "2. Sprawdź typy kolumn.\n",
    "3. Wczytaj plik ponownie, jawnie definiując:\n",
    "   - kolumny numeryczne jako `float64`,\n",
    "   - kolumnę kategoryczną jako `category`,\n",
    "   - kolumnę daty przez `parse_dates` (wynikowo `datetime64[ns]`).\n",
    "4. Porównaj `df.info()` dla obu wersji.\n",
    "\n",
    "Wymagane funkcje:\n",
    "\n",
    "- `pd.read_csv()`\n",
    "- `DataFrame.info()`\n",
    "- parametr `dtype`\n",
    "- parametr `parse_dates`\n",
    "\n",
    "Kryterium zaliczenia:\n",
    "\n",
    "- w drugim imporcie kolumna daty ma typ `datetime64[ns]`,\n",
    "- co najmniej jedna kolumna ma typ `category`.\n",
    "\n",
    "Checkpoint:\n",
    "\n",
    "- pokaż prowadzącemu wynik `df.info()` dla obu wersji.\n",
    "\n",
    "Dokumentacja:\n",
    "\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1ebab8-0690-4782-99a1-c329e5f3ddb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miejsce na Twoje rozwiązanie.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6bfb39-9988-4bf4-9170-cb9a8f8d341f",
   "metadata": {},
   "source": [
    "## Zadanie 3\n",
    "\n",
    "Cel: diagnostyka błędów parsowania.\n",
    "\n",
    "Instrukcja:\n",
    "\n",
    "1. Spróbuj wczytać `data_semicolon.csv` domyślnie.\n",
    "2. Zidentyfikuj problem.\n",
    "3. Ustaw poprawny separator.\n",
    "4. W razie potrzeby ustaw `encoding='utf-8'` lub `encoding='latin1'`.\n",
    "5. Zweryfikuj poprawność nagłówków.\n",
    "\n",
    "Wymagane funkcje:\n",
    "\n",
    "- `pd.read_csv()`\n",
    "- parametr `sep`\n",
    "- parametr `encoding`\n",
    "- `DataFrame.columns`\n",
    "\n",
    "Kryterium zaliczenia:\n",
    "\n",
    "- kolumny są rozdzielone poprawnie,\n",
    "- nagłówki nie zawierają artefaktów kodowania.\n",
    "\n",
    "Checkpoint:\n",
    "\n",
    "- pokaż `df.head()` i `df.columns`.\n",
    "\n",
    "Dokumentacja:\n",
    "\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a5599f-52bd-4788-9db0-94d0dbebe63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miejsce na Twoje rozwiązanie.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279a7f48-0b64-4ab0-a26e-f2ba890787c6",
   "metadata": {},
   "source": [
    "## Zadanie 4\n",
    "\n",
    "Cel: zrozumienie, jak parser interpretuje wartości brakujące.\n",
    "\n",
    "Instrukcja:\n",
    "\n",
    "1. Wczytaj `missing_values.csv`.\n",
    "2. Ustaw własne oznaczenia NA: `.` oraz `999`.\n",
    "3. Sprawdź liczbę braków w każdej kolumnie.\n",
    "\n",
    "Wymagane funkcje:\n",
    "\n",
    "- `pd.read_csv()`\n",
    "- parametr `na_values`\n",
    "- `DataFrame.isna()`\n",
    "- `DataFrame.sum()`\n",
    "\n",
    "Kryterium zaliczenia:\n",
    "\n",
    "- `.` i `999` są liczone jako braki danych.\n",
    "\n",
    "Checkpoint:\n",
    "\n",
    "- pokaż wynik `df.isna().sum()`.\n",
    "\n",
    "Dokumentacja:\n",
    "\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isna.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b46400a-4bcb-44f7-86b7-7575c96bb55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miejsce na Twoje rozwiązanie.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9b96fc-d317-4332-b22a-bbb9dbb16eb5",
   "metadata": {},
   "source": [
    "## Zadanie 5\n",
    "\n",
    "Cel: zrozumienie struktury pliku Excel jako kontenera wielu arkuszy.\n",
    "\n",
    "Instrukcja:\n",
    "\n",
    "1. Wczytaj `experiment.xlsx`.\n",
    "2. Załaduj:\n",
    "   - jeden arkusz,\n",
    "   - wszystkie arkusze jako słownik.\n",
    "3. Sprawdź strukturę zwróconego obiektu.\n",
    "\n",
    "Wymagane funkcje:\n",
    "\n",
    "- `pd.read_excel()`\n",
    "- parametr `sheet_name`\n",
    "\n",
    "Kryterium zaliczenia:\n",
    "\n",
    "- poprawnie odczytujesz pojedynczy arkusz oraz słownik arkuszy.\n",
    "\n",
    "Checkpoint:\n",
    "\n",
    "- pokaż typ obiektu dla `sheet_name=None` i nazwy kluczy.\n",
    "\n",
    "Dokumentacja:\n",
    "\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a5c81d-0f3c-442c-bedb-9432998eebbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miejsce na Twoje rozwiązanie.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fa4428-94f2-4544-a0ef-358d13721253",
   "metadata": {},
   "source": [
    "## Zadanie 6\n",
    "\n",
    "Cel: ograniczenie importu do wybranych kolumn i wierszy.\n",
    "\n",
    "Instrukcja:\n",
    "\n",
    "1. Wczytaj z `experiment.xlsx` tylko wybrane kolumny.\n",
    "2. Pomiń pierwsze dwa wiersze.\n",
    "3. Ustaw własne nazwy kolumn.\n",
    "\n",
    "Wymagane funkcje:\n",
    "\n",
    "- `pd.read_excel()`\n",
    "- parametr `usecols`\n",
    "- parametr `skiprows`\n",
    "- parametr `names`\n",
    "- parametr `header` (ustaw `header=None`, jeśli ręcznie podajesz `names`)\n",
    "\n",
    "Kryterium zaliczenia:\n",
    "\n",
    "- wynikowa tabela ma dokładnie wskazane kolumny i nazwy.\n",
    "\n",
    "Checkpoint:\n",
    "\n",
    "- pokaż `df.head()` oraz `df.columns`.\n",
    "\n",
    "Dokumentacja:\n",
    "\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b8f55c-8373-413e-a843-be0622aad420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miejsce na Twoje rozwiązanie.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949d3caf-01c1-44c5-8e4a-fa46519778b3",
   "metadata": {},
   "source": [
    "## Zadanie 7\n",
    "\n",
    "Cel: zrozumienie różnicy między strukturą tabelaryczną a JSON.\n",
    "\n",
    "Instrukcja:\n",
    "\n",
    "1. Wczytaj `data.json`.\n",
    "2. Sprawdź strukturę danych.\n",
    "3. Przekonwertuj dane do `DataFrame`.\n",
    "\n",
    "Wymagane funkcje:\n",
    "\n",
    "- `pd.read_json()`\n",
    "- `pd.DataFrame()`\n",
    "\n",
    "Kryterium zaliczenia:\n",
    "\n",
    "- poprawnie uzyskany `DataFrame` z oczekiwaną liczbą wierszy i kolumn.\n",
    "\n",
    "Checkpoint:\n",
    "\n",
    "- pokaż `df.head()` i `df.shape`.\n",
    "\n",
    "Dokumentacja:\n",
    "\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.read_json.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c050e5d0-848e-4ad8-a6dd-3fb88014a0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miejsce na Twoje rozwiązanie.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1567d7-105e-4199-872e-0efe2fb56db1",
   "metadata": {},
   "source": [
    "## Zadanie 8\n",
    "\n",
    "Cel: normalizacja struktury zagnieżdżonej.\n",
    "\n",
    "Instrukcja:\n",
    "\n",
    "1. Wczytaj `data_nested.json`.\n",
    "2. Zidentyfikuj pola zawierające słowniki/listy.\n",
    "3. Spłaszcz strukturę do postaci tabelarycznej.\n",
    "\n",
    "Wymagane funkcje:\n",
    "\n",
    "- `pd.read_json()`\n",
    "- `pd.json_normalize()`\n",
    "\n",
    "Kryterium zaliczenia:\n",
    "\n",
    "- kolumny z danych zagnieżdżonych są poprawnie wypłaszczone.\n",
    "\n",
    "Checkpoint:\n",
    "\n",
    "- pokaż listę kolumn i `head()` po normalizacji.\n",
    "\n",
    "Dokumentacja:\n",
    "\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.json_normalize.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f641d54-5a04-4fc7-b755-6d0b63d7e0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miejsce na Twoje rozwiązanie.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (analiza-venv)",
   "language": "python",
   "name": "analiza-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}